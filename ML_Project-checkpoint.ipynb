{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "dOfQ8mAraPtv"
   },
   "outputs": [],
   "source": [
    "#READING A DATA FILE TAGS range from 0 to len(data)\n",
    "import gensim\n",
    "import pandas as pd\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpus(fname, tokens_only=False):\n",
    "    with open(fname, encoding=\"iso-8859-1\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            tokens = gensim.utils.simple_preprocess(line)\n",
    "            if tokens_only:\n",
    "                yield tokens\n",
    "            else:\n",
    "                # For training data, add tags\n",
    "                yield gensim.models.doc2vec.TaggedDocument(tokens, [i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS CREATES A TRAINING CORPUS\n",
    "#train_corpus = list(read_corpus(\"train.txt\"))\n",
    "train_corpus = list(read_corpus(\"train.txt\"))\n",
    "train_corpus1 = pd.DataFrame(read_corpus(\"train.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "EDCjVKTIaPt0",
    "outputId": "52a0e125-49b1-43bc-f8eb-839b6b35546a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['we', 'stayed', 'at', 'the', 'schicago', 'hilton', 'for', 'days', 'and', 'nights', 'for', 'conference', 'have', 'to', 'say', 'normally', 'am', 'very', 'easy', 'going', 'about', 'amenities', 'cleanliness', 'and', 'the', 'like', 'however', 'our', 'experience', 'at', 'the', 'hilton', 'was', 'so', 'awful', 'am', 'taking', 'the', 'time', 'to', 'actually', 'write', 'this', 'review', 'truly', 'do', 'not', 'stay', 'at', 'this', 'hotel', 'when', 'we', 'arrived', 'in', 'our', 'room', 'it', 'was', 'clear', 'that', 'the', 'carpet', 'hadn', 'been', 'vacuumed', 'figuered', 'okay', 'it', 'just', 'the', 'carpet', 'until', 'saw', 'the', 'bathroom', 'although', 'the', 'bathroom', 'had', 'all', 'the', 'superficial', 'indicators', 'of', 'housekeeping', 'having', 'recently', 'cleaned', 'paper', 'band', 'across', 'the', 'toilet', 'paper', 'caps', 'on', 'the', 'drinking', 'glasses', 'etc', 'it', 'was', 'clear', 'that', 'no', 'actual', 'cleaning', 'took', 'place', 'there', 'was', 'spot', 'probably', 'urine', 'on', 'the', 'toilet', 'seat', 'and', 'kid', 'you', 'not', 'the', 'remnants', 'of', 'lip', 'smudge', 'on', 'the', 'glass', 'know', 'people', 'who', 'have', 'worked', 'many', 'years', 'in', 'the', 'hotel', 'industry', 'and', 'they', 'always', 'warned', 'that', 'lazy', 'housekeeping', 'will', 'make', 'things', 'appear', 'clean', 'but', 'in', 'fact', 'they', 'make', 'no', 'effort', 'to', 'keep', 'things', 'sanitary', 'well', 'the', 'hilton', 'was', 'proof', 'called', 'downstairs', 'and', 'complained', 'and', 'they', 'sent', 'up', 'chambermaid', 'hours', 'later', 'frankly', 'found', 'the', 'room', 'disgusting', 'the', 'hotel', 'itself', 'outside', 'the', 'rooms', 'was', 'cavernous', 'and', 'unwelcoming', 'with', 'an', 'awful', 'echo', 'in', 'the', 'lobby', 'area', 'that', 'created', 'migraine', 'inducing', 'din', 'rarely', 'have', 'been', 'so', 'eager', 'to', 'leave', 'place', 'as', 'this', 'when', 'got', 'home', 'washed', 'all', 'my', 'clothes', 'whether', 'had', 'worn', 'them', 'or', 'not', 'such', 'was', 'the', 'skeeviness', 'of', 'our', 'accomodations', 'please', 'do', 'yourself', 'favor', 'and', 'stay', 'at', 'clean', 'hotel'], tags=[0])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "-iKVlvj7aPt3"
   },
   "outputs": [],
   "source": [
    "#INSTANTIATE THE GENSIM DOC2VEC MODEL\n",
    "#CREATE VOCABULARY\n",
    "#TRAIN THE GENSIM MODEL USING train_corpus\n",
    "#https://radimrehurek.com/gensim/auto_examples/tutorials/run_doc2vec_lee.html\n",
    "# train the document to vector data with our model\n",
    "model = Doc2Vec(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134836"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.corpus_total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "248"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_corpus[0].words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('totally', 0.9940598011016846),\n",
       " ('shula', 0.992875337600708),\n",
       " ('waiter', 0.9926197528839111),\n",
       " ('finest', 0.992297887802124),\n",
       " ('nowhere', 0.9917033314704895),\n",
       " ('dock', 0.991641104221344),\n",
       " ('member', 0.9912151098251343),\n",
       " ('perhaps', 0.9911155700683594),\n",
       " ('managers', 0.9909864068031311),\n",
       " ('delicious', 0.9908194541931152)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('accomodations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "ssXUaIW1aPt5",
    "outputId": "83a0bb87-9ce0-4d23-b468-2c2411646d3f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.008175</td>\n",
       "      <td>0.039998</td>\n",
       "      <td>-0.002836</td>\n",
       "      <td>-0.054825</td>\n",
       "      <td>-0.128282</td>\n",
       "      <td>-0.137988</td>\n",
       "      <td>-0.066787</td>\n",
       "      <td>0.122645</td>\n",
       "      <td>-0.161304</td>\n",
       "      <td>-0.003425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.080822</td>\n",
       "      <td>0.074147</td>\n",
       "      <td>-0.082629</td>\n",
       "      <td>-0.011750</td>\n",
       "      <td>-0.065255</td>\n",
       "      <td>-0.010610</td>\n",
       "      <td>-0.092663</td>\n",
       "      <td>0.076345</td>\n",
       "      <td>0.107046</td>\n",
       "      <td>0.159362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.029888</td>\n",
       "      <td>0.003010</td>\n",
       "      <td>-0.004347</td>\n",
       "      <td>-0.089725</td>\n",
       "      <td>-0.217871</td>\n",
       "      <td>-0.103073</td>\n",
       "      <td>-0.033170</td>\n",
       "      <td>0.114147</td>\n",
       "      <td>-0.163800</td>\n",
       "      <td>-0.035165</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.086501</td>\n",
       "      <td>-0.014992</td>\n",
       "      <td>0.037972</td>\n",
       "      <td>-0.062545</td>\n",
       "      <td>-0.045712</td>\n",
       "      <td>-0.084737</td>\n",
       "      <td>-0.110416</td>\n",
       "      <td>0.049286</td>\n",
       "      <td>0.117502</td>\n",
       "      <td>0.115292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.022371</td>\n",
       "      <td>-0.071289</td>\n",
       "      <td>0.042272</td>\n",
       "      <td>-0.107610</td>\n",
       "      <td>0.046616</td>\n",
       "      <td>-0.196008</td>\n",
       "      <td>-0.057328</td>\n",
       "      <td>0.054966</td>\n",
       "      <td>-0.157648</td>\n",
       "      <td>0.047962</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018935</td>\n",
       "      <td>0.137161</td>\n",
       "      <td>-0.013007</td>\n",
       "      <td>0.108430</td>\n",
       "      <td>-0.034041</td>\n",
       "      <td>0.002998</td>\n",
       "      <td>-0.087065</td>\n",
       "      <td>-0.125838</td>\n",
       "      <td>0.055214</td>\n",
       "      <td>0.174420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.025348</td>\n",
       "      <td>-0.011189</td>\n",
       "      <td>0.046921</td>\n",
       "      <td>-0.036261</td>\n",
       "      <td>-0.067579</td>\n",
       "      <td>-0.145750</td>\n",
       "      <td>-0.030569</td>\n",
       "      <td>0.111556</td>\n",
       "      <td>-0.121241</td>\n",
       "      <td>0.004373</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029872</td>\n",
       "      <td>0.072155</td>\n",
       "      <td>-0.047811</td>\n",
       "      <td>-0.003152</td>\n",
       "      <td>-0.054482</td>\n",
       "      <td>0.021205</td>\n",
       "      <td>-0.063718</td>\n",
       "      <td>-0.009837</td>\n",
       "      <td>0.089423</td>\n",
       "      <td>0.144787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.074588</td>\n",
       "      <td>-0.031337</td>\n",
       "      <td>0.069827</td>\n",
       "      <td>-0.016949</td>\n",
       "      <td>-0.007830</td>\n",
       "      <td>-0.198389</td>\n",
       "      <td>-0.042748</td>\n",
       "      <td>0.103644</td>\n",
       "      <td>-0.185405</td>\n",
       "      <td>0.003117</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020077</td>\n",
       "      <td>0.051311</td>\n",
       "      <td>0.035218</td>\n",
       "      <td>0.101689</td>\n",
       "      <td>-0.065193</td>\n",
       "      <td>-0.034644</td>\n",
       "      <td>-0.059872</td>\n",
       "      <td>-0.057701</td>\n",
       "      <td>0.042536</td>\n",
       "      <td>0.125516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>-0.014255</td>\n",
       "      <td>0.022244</td>\n",
       "      <td>-0.017077</td>\n",
       "      <td>-0.113506</td>\n",
       "      <td>-0.073795</td>\n",
       "      <td>-0.019202</td>\n",
       "      <td>-0.033635</td>\n",
       "      <td>0.054933</td>\n",
       "      <td>-0.058667</td>\n",
       "      <td>-0.016521</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.067867</td>\n",
       "      <td>-0.018402</td>\n",
       "      <td>-0.041170</td>\n",
       "      <td>-0.036189</td>\n",
       "      <td>-0.036528</td>\n",
       "      <td>0.004336</td>\n",
       "      <td>-0.082327</td>\n",
       "      <td>0.034155</td>\n",
       "      <td>0.072757</td>\n",
       "      <td>0.032032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>-0.031589</td>\n",
       "      <td>0.006530</td>\n",
       "      <td>-0.025731</td>\n",
       "      <td>-0.162054</td>\n",
       "      <td>-0.066449</td>\n",
       "      <td>-0.003798</td>\n",
       "      <td>0.010970</td>\n",
       "      <td>0.039348</td>\n",
       "      <td>-0.019583</td>\n",
       "      <td>-0.027836</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.051588</td>\n",
       "      <td>-0.023184</td>\n",
       "      <td>-0.038463</td>\n",
       "      <td>-0.052151</td>\n",
       "      <td>-0.017539</td>\n",
       "      <td>0.056539</td>\n",
       "      <td>-0.086415</td>\n",
       "      <td>0.010267</td>\n",
       "      <td>0.093712</td>\n",
       "      <td>0.023707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>-0.101361</td>\n",
       "      <td>-0.041394</td>\n",
       "      <td>-0.070144</td>\n",
       "      <td>-0.179122</td>\n",
       "      <td>-0.039658</td>\n",
       "      <td>-0.021732</td>\n",
       "      <td>-0.019738</td>\n",
       "      <td>0.081432</td>\n",
       "      <td>-0.041655</td>\n",
       "      <td>0.005249</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034296</td>\n",
       "      <td>0.008339</td>\n",
       "      <td>-0.042928</td>\n",
       "      <td>-0.072137</td>\n",
       "      <td>0.002721</td>\n",
       "      <td>0.020870</td>\n",
       "      <td>-0.137732</td>\n",
       "      <td>-0.008742</td>\n",
       "      <td>0.078527</td>\n",
       "      <td>0.067092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>0.023432</td>\n",
       "      <td>-0.001544</td>\n",
       "      <td>0.009168</td>\n",
       "      <td>-0.071267</td>\n",
       "      <td>-0.013500</td>\n",
       "      <td>-0.043881</td>\n",
       "      <td>0.004958</td>\n",
       "      <td>0.008790</td>\n",
       "      <td>-0.030141</td>\n",
       "      <td>-0.014968</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016603</td>\n",
       "      <td>0.022716</td>\n",
       "      <td>-0.034309</td>\n",
       "      <td>0.046775</td>\n",
       "      <td>-0.023701</td>\n",
       "      <td>0.017747</td>\n",
       "      <td>-0.003603</td>\n",
       "      <td>0.024834</td>\n",
       "      <td>0.035814</td>\n",
       "      <td>0.016300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>-0.001251</td>\n",
       "      <td>-0.005149</td>\n",
       "      <td>0.014162</td>\n",
       "      <td>-0.178922</td>\n",
       "      <td>-0.066303</td>\n",
       "      <td>-0.097904</td>\n",
       "      <td>-0.023189</td>\n",
       "      <td>0.063342</td>\n",
       "      <td>-0.100906</td>\n",
       "      <td>-0.019854</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.065889</td>\n",
       "      <td>0.026675</td>\n",
       "      <td>-0.032112</td>\n",
       "      <td>0.017280</td>\n",
       "      <td>-0.040022</td>\n",
       "      <td>0.058634</td>\n",
       "      <td>-0.062096</td>\n",
       "      <td>-0.054539</td>\n",
       "      <td>0.090669</td>\n",
       "      <td>0.097487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>963 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6   \\\n",
       "0    0.008175  0.039998 -0.002836 -0.054825 -0.128282 -0.137988 -0.066787   \n",
       "1    0.029888  0.003010 -0.004347 -0.089725 -0.217871 -0.103073 -0.033170   \n",
       "2   -0.022371 -0.071289  0.042272 -0.107610  0.046616 -0.196008 -0.057328   \n",
       "3    0.025348 -0.011189  0.046921 -0.036261 -0.067579 -0.145750 -0.030569   \n",
       "4    0.074588 -0.031337  0.069827 -0.016949 -0.007830 -0.198389 -0.042748   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "958 -0.014255  0.022244 -0.017077 -0.113506 -0.073795 -0.019202 -0.033635   \n",
       "959 -0.031589  0.006530 -0.025731 -0.162054 -0.066449 -0.003798  0.010970   \n",
       "960 -0.101361 -0.041394 -0.070144 -0.179122 -0.039658 -0.021732 -0.019738   \n",
       "961  0.023432 -0.001544  0.009168 -0.071267 -0.013500 -0.043881  0.004958   \n",
       "962 -0.001251 -0.005149  0.014162 -0.178922 -0.066303 -0.097904 -0.023189   \n",
       "\n",
       "           7         8         9   ...        90        91        92  \\\n",
       "0    0.122645 -0.161304 -0.003425  ... -0.080822  0.074147 -0.082629   \n",
       "1    0.114147 -0.163800 -0.035165  ... -0.086501 -0.014992  0.037972   \n",
       "2    0.054966 -0.157648  0.047962  ... -0.018935  0.137161 -0.013007   \n",
       "3    0.111556 -0.121241  0.004373  ... -0.029872  0.072155 -0.047811   \n",
       "4    0.103644 -0.185405  0.003117  ... -0.020077  0.051311  0.035218   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "958  0.054933 -0.058667 -0.016521  ... -0.067867 -0.018402 -0.041170   \n",
       "959  0.039348 -0.019583 -0.027836  ... -0.051588 -0.023184 -0.038463   \n",
       "960  0.081432 -0.041655  0.005249  ... -0.034296  0.008339 -0.042928   \n",
       "961  0.008790 -0.030141 -0.014968  ... -0.016603  0.022716 -0.034309   \n",
       "962  0.063342 -0.100906 -0.019854  ... -0.065889  0.026675 -0.032112   \n",
       "\n",
       "           93        94        95        96        97        98        99  \n",
       "0   -0.011750 -0.065255 -0.010610 -0.092663  0.076345  0.107046  0.159362  \n",
       "1   -0.062545 -0.045712 -0.084737 -0.110416  0.049286  0.117502  0.115292  \n",
       "2    0.108430 -0.034041  0.002998 -0.087065 -0.125838  0.055214  0.174420  \n",
       "3   -0.003152 -0.054482  0.021205 -0.063718 -0.009837  0.089423  0.144787  \n",
       "4    0.101689 -0.065193 -0.034644 -0.059872 -0.057701  0.042536  0.125516  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "958 -0.036189 -0.036528  0.004336 -0.082327  0.034155  0.072757  0.032032  \n",
       "959 -0.052151 -0.017539  0.056539 -0.086415  0.010267  0.093712  0.023707  \n",
       "960 -0.072137  0.002721  0.020870 -0.137732 -0.008742  0.078527  0.067092  \n",
       "961  0.046775 -0.023701  0.017747 -0.003603  0.024834  0.035814  0.016300  \n",
       "962  0.017280 -0.040022  0.058634 -0.062096 -0.054539  0.090669  0.097487  \n",
       "\n",
       "[963 rows x 100 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://radimrehurek.com/gensim/auto_examples/tutorials/run_doc2vec_lee.html\n",
    "#stack all the vectors using numpy.vstack() to obtain X (features for classifier)\n",
    "#GET THE FEATURE VECTORS for a specific training instance in train_corpus using infer_vector()\n",
    "#Read the labels in trainlabels.txt to obtain Y\n",
    "doc2vec = train_corpus1[\"words\"].apply(lambda x: model.infer_vector(x)).apply(pd.Series)\n",
    "doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "rQVLW0graPt8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = list(open(\"trainlabels.txt\", \"r\"))\n",
    "labels = [x[:-1] if x.endswith('\\n') else x for x in labels]\n",
    "for i in range(0, len(labels)):\n",
    "    labels[i] = int(labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "msX3MBxyaPuF",
    "outputId": "54a56f3c-964f-4de3-b356-e65d96f13ded"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.021582</td>\n",
       "      <td>-0.046496</td>\n",
       "      <td>0.053308</td>\n",
       "      <td>-0.127038</td>\n",
       "      <td>-0.038073</td>\n",
       "      <td>-0.232868</td>\n",
       "      <td>-0.047264</td>\n",
       "      <td>0.109214</td>\n",
       "      <td>-0.164279</td>\n",
       "      <td>0.034177</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.044140</td>\n",
       "      <td>0.108195</td>\n",
       "      <td>0.063129</td>\n",
       "      <td>0.062881</td>\n",
       "      <td>-0.044003</td>\n",
       "      <td>0.017982</td>\n",
       "      <td>-0.136294</td>\n",
       "      <td>-0.103158</td>\n",
       "      <td>0.113706</td>\n",
       "      <td>0.151570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001028</td>\n",
       "      <td>0.020624</td>\n",
       "      <td>-0.001765</td>\n",
       "      <td>-0.014688</td>\n",
       "      <td>-0.049445</td>\n",
       "      <td>0.001862</td>\n",
       "      <td>0.026724</td>\n",
       "      <td>-0.006519</td>\n",
       "      <td>0.015557</td>\n",
       "      <td>-0.011908</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020672</td>\n",
       "      <td>0.012812</td>\n",
       "      <td>-0.022885</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>-0.010602</td>\n",
       "      <td>0.036768</td>\n",
       "      <td>0.016185</td>\n",
       "      <td>0.054006</td>\n",
       "      <td>0.039803</td>\n",
       "      <td>0.016917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.060290</td>\n",
       "      <td>0.022868</td>\n",
       "      <td>0.056276</td>\n",
       "      <td>-0.014326</td>\n",
       "      <td>-0.084202</td>\n",
       "      <td>-0.143945</td>\n",
       "      <td>-0.052279</td>\n",
       "      <td>0.073676</td>\n",
       "      <td>-0.136644</td>\n",
       "      <td>-0.023303</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.080866</td>\n",
       "      <td>0.050864</td>\n",
       "      <td>0.008007</td>\n",
       "      <td>0.034167</td>\n",
       "      <td>-0.073468</td>\n",
       "      <td>0.009570</td>\n",
       "      <td>-0.034373</td>\n",
       "      <td>-0.011007</td>\n",
       "      <td>0.064035</td>\n",
       "      <td>0.109186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.065193</td>\n",
       "      <td>-0.003272</td>\n",
       "      <td>0.061504</td>\n",
       "      <td>-0.012472</td>\n",
       "      <td>-0.087282</td>\n",
       "      <td>-0.162091</td>\n",
       "      <td>-0.040303</td>\n",
       "      <td>0.074995</td>\n",
       "      <td>-0.170042</td>\n",
       "      <td>-0.015415</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031273</td>\n",
       "      <td>0.003168</td>\n",
       "      <td>0.087850</td>\n",
       "      <td>0.056165</td>\n",
       "      <td>-0.055420</td>\n",
       "      <td>-0.074362</td>\n",
       "      <td>-0.042052</td>\n",
       "      <td>-0.008437</td>\n",
       "      <td>0.025927</td>\n",
       "      <td>0.071095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.037179</td>\n",
       "      <td>0.037976</td>\n",
       "      <td>-0.054102</td>\n",
       "      <td>-0.281608</td>\n",
       "      <td>-0.313254</td>\n",
       "      <td>-0.074483</td>\n",
       "      <td>-0.032066</td>\n",
       "      <td>0.161114</td>\n",
       "      <td>-0.122175</td>\n",
       "      <td>-0.057937</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.199807</td>\n",
       "      <td>-0.035629</td>\n",
       "      <td>-0.039506</td>\n",
       "      <td>-0.161779</td>\n",
       "      <td>-0.085469</td>\n",
       "      <td>0.047482</td>\n",
       "      <td>-0.222928</td>\n",
       "      <td>0.064221</td>\n",
       "      <td>0.247850</td>\n",
       "      <td>0.146076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>-0.042311</td>\n",
       "      <td>-0.026978</td>\n",
       "      <td>-0.018252</td>\n",
       "      <td>-0.272105</td>\n",
       "      <td>-0.111961</td>\n",
       "      <td>-0.114909</td>\n",
       "      <td>-0.032050</td>\n",
       "      <td>0.129187</td>\n",
       "      <td>-0.185030</td>\n",
       "      <td>-0.064368</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087119</td>\n",
       "      <td>-0.034983</td>\n",
       "      <td>0.024697</td>\n",
       "      <td>-0.040663</td>\n",
       "      <td>-0.065187</td>\n",
       "      <td>-0.017025</td>\n",
       "      <td>-0.180324</td>\n",
       "      <td>-0.040125</td>\n",
       "      <td>0.131963</td>\n",
       "      <td>0.081471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>-0.003953</td>\n",
       "      <td>-0.007371</td>\n",
       "      <td>-0.015697</td>\n",
       "      <td>-0.224239</td>\n",
       "      <td>-0.060655</td>\n",
       "      <td>0.016578</td>\n",
       "      <td>-0.012979</td>\n",
       "      <td>0.037069</td>\n",
       "      <td>-0.045395</td>\n",
       "      <td>-0.054252</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057766</td>\n",
       "      <td>-0.073749</td>\n",
       "      <td>-0.020102</td>\n",
       "      <td>-0.033960</td>\n",
       "      <td>-0.038249</td>\n",
       "      <td>0.030680</td>\n",
       "      <td>-0.063019</td>\n",
       "      <td>-0.018269</td>\n",
       "      <td>0.056575</td>\n",
       "      <td>-0.045512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>-0.007680</td>\n",
       "      <td>-0.003045</td>\n",
       "      <td>-0.012354</td>\n",
       "      <td>-0.088179</td>\n",
       "      <td>-0.052203</td>\n",
       "      <td>-0.037643</td>\n",
       "      <td>-0.013328</td>\n",
       "      <td>0.051298</td>\n",
       "      <td>-0.058374</td>\n",
       "      <td>-0.020340</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039596</td>\n",
       "      <td>-0.008613</td>\n",
       "      <td>0.005262</td>\n",
       "      <td>-0.025575</td>\n",
       "      <td>-0.021502</td>\n",
       "      <td>-0.018230</td>\n",
       "      <td>-0.056298</td>\n",
       "      <td>-0.004002</td>\n",
       "      <td>0.057643</td>\n",
       "      <td>0.023912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.047202</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>0.044453</td>\n",
       "      <td>-0.007527</td>\n",
       "      <td>-0.068666</td>\n",
       "      <td>-0.094566</td>\n",
       "      <td>-0.006695</td>\n",
       "      <td>0.035522</td>\n",
       "      <td>-0.067905</td>\n",
       "      <td>0.004843</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035163</td>\n",
       "      <td>0.041948</td>\n",
       "      <td>-0.002599</td>\n",
       "      <td>0.038632</td>\n",
       "      <td>-0.029601</td>\n",
       "      <td>-0.004257</td>\n",
       "      <td>-0.008698</td>\n",
       "      <td>0.010647</td>\n",
       "      <td>0.036414</td>\n",
       "      <td>0.087140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.003218</td>\n",
       "      <td>-0.002324</td>\n",
       "      <td>-0.001402</td>\n",
       "      <td>-0.171993</td>\n",
       "      <td>-0.097085</td>\n",
       "      <td>-0.109552</td>\n",
       "      <td>-0.053533</td>\n",
       "      <td>0.076399</td>\n",
       "      <td>-0.133671</td>\n",
       "      <td>-0.036610</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.080538</td>\n",
       "      <td>0.018731</td>\n",
       "      <td>-0.024307</td>\n",
       "      <td>0.035747</td>\n",
       "      <td>-0.049826</td>\n",
       "      <td>-0.022577</td>\n",
       "      <td>-0.059524</td>\n",
       "      <td>0.044299</td>\n",
       "      <td>0.062892</td>\n",
       "      <td>0.068318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6   \\\n",
       "0   -0.021582 -0.046496  0.053308 -0.127038 -0.038073 -0.232868 -0.047264   \n",
       "1   -0.001028  0.020624 -0.001765 -0.014688 -0.049445  0.001862  0.026724   \n",
       "2    0.060290  0.022868  0.056276 -0.014326 -0.084202 -0.143945 -0.052279   \n",
       "3    0.065193 -0.003272  0.061504 -0.012472 -0.087282 -0.162091 -0.040303   \n",
       "4   -0.037179  0.037976 -0.054102 -0.281608 -0.313254 -0.074483 -0.032066   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "113 -0.042311 -0.026978 -0.018252 -0.272105 -0.111961 -0.114909 -0.032050   \n",
       "114 -0.003953 -0.007371 -0.015697 -0.224239 -0.060655  0.016578 -0.012979   \n",
       "115 -0.007680 -0.003045 -0.012354 -0.088179 -0.052203 -0.037643 -0.013328   \n",
       "116  0.047202  0.000437  0.044453 -0.007527 -0.068666 -0.094566 -0.006695   \n",
       "117  0.003218 -0.002324 -0.001402 -0.171993 -0.097085 -0.109552 -0.053533   \n",
       "\n",
       "           7         8         9   ...        90        91        92  \\\n",
       "0    0.109214 -0.164279  0.034177  ... -0.044140  0.108195  0.063129   \n",
       "1   -0.006519  0.015557 -0.011908  ... -0.020672  0.012812 -0.022885   \n",
       "2    0.073676 -0.136644 -0.023303  ... -0.080866  0.050864  0.008007   \n",
       "3    0.074995 -0.170042 -0.015415  ... -0.031273  0.003168  0.087850   \n",
       "4    0.161114 -0.122175 -0.057937  ... -0.199807 -0.035629 -0.039506   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "113  0.129187 -0.185030 -0.064368  ... -0.087119 -0.034983  0.024697   \n",
       "114  0.037069 -0.045395 -0.054252  ... -0.057766 -0.073749 -0.020102   \n",
       "115  0.051298 -0.058374 -0.020340  ... -0.039596 -0.008613  0.005262   \n",
       "116  0.035522 -0.067905  0.004843  ... -0.035163  0.041948 -0.002599   \n",
       "117  0.076399 -0.133671 -0.036610  ... -0.080538  0.018731 -0.024307   \n",
       "\n",
       "           93        94        95        96        97        98        99  \n",
       "0    0.062881 -0.044003  0.017982 -0.136294 -0.103158  0.113706  0.151570  \n",
       "1    0.000298 -0.010602  0.036768  0.016185  0.054006  0.039803  0.016917  \n",
       "2    0.034167 -0.073468  0.009570 -0.034373 -0.011007  0.064035  0.109186  \n",
       "3    0.056165 -0.055420 -0.074362 -0.042052 -0.008437  0.025927  0.071095  \n",
       "4   -0.161779 -0.085469  0.047482 -0.222928  0.064221  0.247850  0.146076  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "113 -0.040663 -0.065187 -0.017025 -0.180324 -0.040125  0.131963  0.081471  \n",
       "114 -0.033960 -0.038249  0.030680 -0.063019 -0.018269  0.056575 -0.045512  \n",
       "115 -0.025575 -0.021502 -0.018230 -0.056298 -0.004002  0.057643  0.023912  \n",
       "116  0.038632 -0.029601 -0.004257 -0.008698  0.010647  0.036414  0.087140  \n",
       "117  0.035747 -0.049826 -0.022577 -0.059524  0.044299  0.062892  0.068318  \n",
       "\n",
       "[118 rows x 100 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tune parameters on the validation dataset\n",
    "#Follow the same feature extraction procedure for validation data as you did for the training data \n",
    "#except do not re-train the gensim model simply obtain vectors using model.infer_vector()\n",
    "valid_corpus1 = pd.DataFrame(read_corpus(\"validation.txt\"))\n",
    "\n",
    "y_valid = list(open(\"validationlabels.txt\", \"r\"))\n",
    "y_valid = [x[:-1] if x.endswith('\\n') else x for x in y_valid]\n",
    "for i in range(0, len(y_valid)):\n",
    "    y_valid[i] = int(y_valid[i])\n",
    "\n",
    "doc2vec1 = valid_corpus1[\"words\"].apply(lambda x: model.infer_vector(x)).apply(pd.Series)\n",
    "doc2vec1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(random_state=42),\n",
       "             param_grid={'max_depth': [4, 5, 6, 7, 8],\n",
       "                         'max_features': ['sqrt', 0.25, 0.5, 0.75, 1.0],\n",
       "                         'n_estimators': [10, 30, 50, 100]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomf = RandomForestClassifier(n_estimators = 100, random_state = 42)\n",
    "logreg = LogisticRegression(random_state=0)\n",
    "clf = MLPClassifier(random_state=1, max_iter=300)\n",
    "\n",
    "grid_values = {'n_estimators':[10, 30, 50, 100],\n",
    "              'max_features':['sqrt',0.25,0.5,0.75,1.0],\n",
    "              'max_depth':[4,5,6,7,8]}\n",
    "\n",
    "randomf.fit(doc2vec, labels)\n",
    "logreg.fit(doc2vec, labels)\n",
    "clf.fit(doc2vec, labels)\n",
    "\n",
    "grid_search_rfc = GridSearchCV(randomf, param_grid = grid_values, scoring = 'accuracy')\n",
    "#grid_search_lr = GridSearchCV(logreg, param_grid = grid_values, scoring = 'accuracy')\n",
    "#grid_search_clf = GridSearchCV(clf, param_grid = grid_values, scoring = 'accuracy')\n",
    "\n",
    "grid_search_rfc.fit(doc2vec, labels)\n",
    "#grid_search_lr.fit(doc2vec, labels)\n",
    "#grid_search_clf.fit(doc2vec, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_values1 = {'random_state':[1,20,30,50,100], \n",
    "                'max_iter':[1,2,20,30,100]}\n",
    "\n",
    "logreg.fit(doc2vec, labels)\n",
    "clf.fit(doc2vec, labels)\n",
    "\n",
    "grid_search_lr = GridSearchCV(logreg, param_grid = grid_values1, scoring = 'accuracy')\n",
    "grid_search_clf = GridSearchCV(clf, param_grid = grid_values1, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(random_state=0),\n",
       "             param_grid={'max_iter': [1, 2, 20, 30, 100],\n",
       "                         'random_state': [1, 20, 30, 50, 100]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_lr.fit(doc2vec, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=MLPClassifier(max_iter=300, random_state=1),\n",
       "             param_grid={'max_iter': [1, 2, 20, 30, 100],\n",
       "                         'random_state': [1, 20, 30, 50, 100]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_clf.fit(doc2vec, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 8, 'max_features': 0.25, 'n_estimators': 100}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_rfc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_iter': 20, 'random_state': 1}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_lr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_iter': 100, 'random_state': 100}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
       "       0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_rfc.predict(doc2vec1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_lr.predict(doc2vec1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1,\n",
       "       0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_clf.predict(doc2vec1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.55      0.62        58\n",
      "           1       0.64      0.77      0.70        60\n",
      "\n",
      "    accuracy                           0.66       118\n",
      "   macro avg       0.67      0.66      0.66       118\n",
      "weighted avg       0.67      0.66      0.66       118\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_valid, grid_search_rfc.predict(doc2vec1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.55      0.61        58\n",
      "           1       0.63      0.75      0.69        60\n",
      "\n",
      "    accuracy                           0.65       118\n",
      "   macro avg       0.66      0.65      0.65       118\n",
      "weighted avg       0.66      0.65      0.65       118\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid, grid_search_lr.predict(doc2vec1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.60      0.64        58\n",
      "           1       0.66      0.73      0.69        60\n",
      "\n",
      "    accuracy                           0.67       118\n",
      "   macro avg       0.67      0.67      0.67       118\n",
      "weighted avg       0.67      0.67      0.67       118\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid, grid_search_clf.predict(doc2vec1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F6IZOeelaPuQ",
    "outputId": "96dd879b-df6e-4f39-ed25-33a61430d8cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.62      0.69        65\n",
      "           1       0.65      0.81      0.72        57\n",
      "\n",
      "    accuracy                           0.70       122\n",
      "   macro avg       0.72      0.71      0.70       122\n",
      "weighted avg       0.72      0.70      0.70       122\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# on test dataset Evaluate precision, recall, f1-score\n",
    "#Follow the same feature extraction procedure as you did for the validation data \n",
    "test_corpus2 = pd.DataFrame(read_corpus(\"test.txt\"))\n",
    "\n",
    "y_test = list(open(\"testlabels.txt\", \"r\"))\n",
    "y_test = [x[:-1] if x.endswith('\\n') else x for x in y_test]\n",
    "for i in range(0, len(y_test)):\n",
    "    y_test[i] = int(y_test[i])\n",
    "\n",
    "doc2vec2 = test_corpus2[\"words\"].apply(lambda x: model.infer_vector(x)).apply(pd.Series)\n",
    "doc2vec2\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, grid_search_rfc.predict(doc2vec2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.63      0.73        65\n",
      "           1       0.68      0.88      0.76        57\n",
      "\n",
      "    accuracy                           0.75       122\n",
      "   macro avg       0.76      0.75      0.74       122\n",
      "weighted avg       0.77      0.75      0.74       122\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, grid_search_lr.predict(doc2vec2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.66      0.75        65\n",
      "           1       0.69      0.88      0.78        57\n",
      "\n",
      "    accuracy                           0.76       122\n",
      "   macro avg       0.78      0.77      0.76       122\n",
      "weighted avg       0.78      0.76      0.76       122\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, grid_search_clf.predict(doc2vec2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.66      0.70       463\n",
      "           1       0.71      0.79      0.75       500\n",
      "\n",
      "    accuracy                           0.72       963\n",
      "   macro avg       0.73      0.72      0.72       963\n",
      "weighted avg       0.73      0.72      0.72       963\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#performance on training set\n",
    "print(classification_report(labels, grid_search_clf.predict(doc2vec)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In both the validation and test sets, logistic regression outperforms the other methods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  When comparing the test and validation sets, the performance on the train set was excellent."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "coded on program-outline.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
